{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFZUb9NUw_DJ"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics==8.0.196 --quiet\n",
        "!pip install matplotlib Pillow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n"
      ],
      "metadata": {
        "id": "8UihsYUmxaHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_0lwwAMWxFQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'your_zip_file.zip' with the name of your zip file\n",
        "zip_file_path = '/content/drive/MyDrive/Models/Segmentation/Model-m/model-m.zip'\n",
        "\n",
        "# Replace 'extraction_path' with the path where you want to extract the contents\n",
        "extraction_path = '/content/'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)"
      ],
      "metadata": {
        "id": "tCdo8jy4xL-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the YOLOv8 model\n",
        "model = YOLO('/content/best.pt')\n",
        "\n",
        "# Open the video file\n",
        "video_path = '/content/drive/MyDrive/dataset_1/Video_4Trim.mp4'\n",
        "cap = cv2.VideoCapture(video_path)"
      ],
      "metadata": {
        "id": "XC1Thqrfxwlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the video file was opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video file.\")\n",
        "    exit()\n",
        "\n",
        "# Get the video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Create a VideoWriter object to save the processed video\n",
        "output_path = '/content/output_video2.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Iterate through each frame of the video\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert frame to PIL image\n",
        "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Perform inference on the frame\n",
        "    results = model(pil_image)\n",
        "\n",
        "    # Extract bounding boxes, classes, names, and confidences\n",
        "    boxes = results[0].boxes.xyxy.tolist()\n",
        "    classes = results[0].boxes.cls.tolist()\n",
        "    names = results[0].names\n",
        "    confidences = results[0].boxes.conf.tolist()\n",
        "\n",
        "    # Plot bounding boxes and labels for the \"open\" and \"Closed\" classes\n",
        "    for box, cls, conf in zip(boxes, classes, confidences):\n",
        "        x1, y1, x2, y2 = box\n",
        "\n",
        "        if names[int(cls)] == \"open\":\n",
        "            # Draw bounding box for \"open\" class\n",
        "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
        "            # Add label for \"open\" class\n",
        "            cv2.putText(frame, f'{names[int(cls)]} {conf:.2f}', (int(x1), int(y1)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "            print(\"Bounding Box Coordinates for the box:\")\n",
        "            print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "        elif names[int(cls)] == \"Closed\":\n",
        "            print('Box Closed')\n",
        "\n",
        "    # Display the frame\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    # Write the frame to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "    # Press 'q' to exit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "UeigcRgIxOxI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}